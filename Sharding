SHARDING TECHNIQUES-
RANGE BASED SHARDING
1.	To make efficient scans possible, the data can be partitioned into ordered and contiguous value ranges by range-sharding. 
2.	However, this approach requires some coordination through a master that manages assignments. 
3.	To ensure elasticity, the system has to be able to detect and resolve hotspots automatically by further splitting an overburdened shard.
Range sharding is supported by wide-column stores like 
•	BigTable, 
•	HBase or 
•	Hypertable and document stores, e.g. MongoDB, RethinkDB, 
•	Espresso and 
•	DocumentDB. 
HASH SHARDING-CONSISTENT HASING
Another way to partition data over several machines is hash-sharding where every data item is assigned to a shard server according to some hash value built from the primary key. 
This approach does not require a coordinator and also guarantees the data to be evenly distributed across the shards, as long as the used hash function produces an even distribution. 
The obvious disadvantage, though, is that it only allows lookups and makes scans unfeasible. Hash sharding is used in key-value stores and is also available in some wide-coloumn stores like Cassandra or Azure Tables.
The shard server that is responsible for a record can be determined as serverid = hash(id)%servers, for example. However, this hashing scheme requires all records to be reassigned every time a new server joins or leaves, because it changes with the number of shard servers (servers). Consequently, it infeasible to use in elastic systems like Dynamo, Riak or Cassandra, which allow additional resources to be added on-demand and again be removed when dispensable. For increased flexibility, elastic systems typically use consistent hashing where records are not directly assigned to servers, but instead to logical partitions which are then distributed across all shard servers. Thus, only a fraction of the data have to be reassigned upon changes in the system topology. For example, an elastic system can be downsized by offloading all logical partitions residing on a particular server to other servers and then shutting down the now idle machine. For details on how consistent hashing is used in NoSQL systems, see the Dynamo paper.

Entity-group sharding is a data partitioning scheme with the goal of enabling single-partition transactions on co-located data. The partitions are called entity-groups and either explicitly declared by the application (e.g. in G-Store andMegaStore) or derived from transactions’ access patterns (e.g. in Relational Cloud and Cloud SQL Server). If a transaction accesses data that spans more than one group, data ownership can be transferred between entity-groups or the transaction manager has to fallback to more expensive multi-node transaction protocols

